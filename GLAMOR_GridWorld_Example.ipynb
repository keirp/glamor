{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rlpyt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0df1da85e65e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mglamor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_world\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_grid_world\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCustomGridWorld\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUniformGridWorldGoalDist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mglamor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_lstm_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEncoderLSTMModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mglamor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projects/vector/glamor_public/glamor/envs/grid_world/custom_grid_world.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrlpyt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEnv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnvStep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrlpyt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_box\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIntBox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnamedtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rlpyt'"
     ]
    }
   ],
   "source": [
    "from glamor.envs.grid_world.custom_grid_world import CustomGridWorld, UniformGridWorldGoalDist\n",
    "from glamor.models.encoder_lstm_model import EncoderLSTMModel\n",
    "from glamor.models.basic.mlp import MLP\n",
    "import torch.nn as nn\n",
    "\n",
    "from glamor.algos.batch_train_glamor import BatchTrainGLAMOR\n",
    "\n",
    "from glamor.utils.logging import disable_wandb\n",
    "\n",
    "disable_wandb('runs/')\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glamor.train.scripts import train_glamor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define environment and task distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_cls = lambda: CustomGridWorld(start_x=3, start_y=3, grid_file='empty_small.txt')\n",
    "env = env_cls()\n",
    "obs = env.reset()\n",
    "obs_shape = obs.shape\n",
    "n_actions = env.action_space.n\n",
    "state_size = 512\n",
    "k = 10\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "task_dist = UniformGridWorldGoalDist(env.grid)\n",
    "task_iter = iter(task_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_render(grid):\n",
    "    frame = np.zeros_like(grid[0])\n",
    "    frame += (grid[0] // 2)\n",
    "    frame += grid[1]\n",
    "    return frame\n",
    "\n",
    "def render_grid(grid):\n",
    "    frame = get_render(grid)\n",
    "    plt.imshow(frame)\n",
    "    \n",
    "render_grid(env._get_grid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model architecture\n",
    "\n",
    "Here we just use a simple MLP to encode observations/goals and an LSTM to model the action distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs rep size: 512, Task rep size: 512, State size: 512\n"
     ]
    }
   ],
   "source": [
    "class GridEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, obs_shape):\n",
    "        super().__init__()\n",
    "        \n",
    "        obs_dim = np.prod(obs_shape)\n",
    "        \n",
    "        self.encoder = MLP(in_dim=obs_dim,\n",
    "                           out_dim=state_size,\n",
    "                           hidden=[128, 128, 128],\n",
    "                           use_layer_norm=True,\n",
    "                           nonlinearity=nn.ReLU)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x / 255.\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        return self.encoder(x)\n",
    "    \n",
    "shared_encoder = GridEncoder(obs_shape)\n",
    "model = EncoderLSTMModel(obs_shape=obs_shape,\n",
    "                         n_actions=n_actions,  \n",
    "                         device=device,\n",
    "                         obs_encoder=shared_encoder,\n",
    "                         task_encoder=shared_encoder,\n",
    "                         obs_rep_size=state_size,\n",
    "                         task_rep_size=state_size,\n",
    "                         state_size=state_size,\n",
    "                         lstm_hidden_dim=64,\n",
    "                         lstm_layers=1,\n",
    "                         lstm_dropout_p=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train GLAMOR\n",
    "\n",
    "This should take shorter than 5 minutes on a CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 5764.94it/s]\n",
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized environment.\n",
      "Generated task distributions.\n",
      "{'x': 0, 'y': 0}\n",
      "{'x': 6, 'y': 6}\n",
      "{'x': 0.6000000000000001, 'y': 0.6000000000000001}\n",
      "Doing 1 batches to 5 trajs.\n",
      "Effective replay ratio: 4.0\n",
      "Replay buffer with obs_buffer shape (100000, 2, 7, 7)\n",
      "Datatypes: obs: uint8, actions: int32\n",
      "Started training.\n",
      "Beginning logging...\n",
      "Evaluating closed_loop_grid_world_goals_label_diff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 50/10000 [00:00<00:50, 197.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs:\n",
      "\tcum_steps: 0\n",
      "\treplay_size: 0\n",
      "\tagent_eps: 1\n",
      "\teval_time: 0.13513422012329102\n",
      "closed_loop_grid_world_goals_label_diff:\n",
      "\tx: 2.8\n",
      "\ty: 1.6\n",
      "\tavg_diff: 2.2\n",
      "\tavg_pos_diff: 0.0\n",
      "\tachieved_x: 0.0\n",
      "\tachieved_y: 0.0\n",
      "\ttotal_achieved: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10050it [00:24, 406.89it/s]                           \n",
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning logging...\n",
      "Evaluating closed_loop_grid_world_goals_label_diff\n",
      "Logs:\n",
      "\tstep_per_sec: 404.85438311087694\n",
      "\tcum_steps: 10050\n",
      "\treplay_size: 10050\n",
      "\tagent_eps: 0.8714285714285714\n",
      "\teval_time: 0.1173858642578125\n",
      "closed_loop_grid_world_goals_label_diff:\n",
      "\tx: 1.6\n",
      "\ty: 0.2\n",
      "\tavg_diff: 0.9\n",
      "\tavg_pos_diff: 0.0\n",
      "\tachieved_x: 0.2\n",
      "\tachieved_y: 0.8\n",
      "\ttotal_achieved: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10050it [00:24, 407.91it/s]                           \n",
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning logging...\n",
      "Evaluating closed_loop_grid_world_goals_label_diff\n",
      "Logs:\n",
      "\tstep_per_sec: 403.92635340310494\n",
      "\tcum_steps: 20100\n",
      "\treplay_size: 20100\n",
      "\tagent_eps: 0.7422142857142857\n",
      "\teval_time: 0.1575918197631836\n",
      "closed_loop_grid_world_goals_label_diff:\n",
      "\tx: 2.2\n",
      "\ty: 0.8\n",
      "\tavg_diff: 1.5\n",
      "\tavg_pos_diff: 0.0\n",
      "\tachieved_x: 0.0\n",
      "\tachieved_y: 0.4\n",
      "\ttotal_achieved: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10050it [00:25, 396.80it/s]                           \n",
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning logging...\n",
      "Evaluating closed_loop_grid_world_goals_label_diff\n",
      "train:\n",
      "\tactions_ce_loss: 1.6769534349441528\n",
      "\tbaseline_actions_loss: 1.7012009620666504\n",
      "\tce_loss: 3.3781542778015137\n",
      "\tmain_loss: 3.3781542778015137\n",
      "Logs:\n",
      "\tstep_per_sec: 392.35641086171876\n",
      "\tcum_steps: 30150\n",
      "\treplay_size: 30150\n",
      "\tagent_eps: 0.6130000000000001\n",
      "\teval_time: 0.1492750644683838\n",
      "closed_loop_grid_world_goals_label_diff:\n",
      "\tx: 1.2\n",
      "\ty: 1.6\n",
      "\tavg_diff: 1.4\n",
      "\tavg_pos_diff: 0.0\n",
      "\tachieved_x: 0.4\n",
      "\tachieved_y: 0.2\n",
      "\ttotal_achieved: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10050it [01:11, 140.38it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning logging...\n",
      "Evaluating closed_loop_grid_world_goals_label_diff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 50/10000 [00:00<00:28, 348.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "\tactions_ce_loss: 1.2314993143081665\n",
      "\tbaseline_actions_loss: 1.552107334136963\n",
      "\tce_loss: 2.78360652923584\n",
      "\tmain_loss: 2.78360652923584\n",
      "Logs:\n",
      "\tstep_per_sec: 139.38698835419052\n",
      "\tcum_steps: 40200\n",
      "\treplay_size: 40200\n",
      "\tagent_eps: 0.48378571428571426\n",
      "\teval_time: 0.23602890968322754\n",
      "closed_loop_grid_world_goals_label_diff:\n",
      "\tx: 0.2\n",
      "\ty: 0.6\n",
      "\tavg_diff: 0.4\n",
      "\tavg_pos_diff: 0.0\n",
      "\tachieved_x: 0.8\n",
      "\tachieved_y: 0.4\n",
      "\ttotal_achieved: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10050it [01:08, 147.41it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning logging...\n",
      "Evaluating closed_loop_grid_world_goals_label_diff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 50/10000 [00:00<00:26, 381.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "\tactions_ce_loss: 1.0115952491760254\n",
      "\tbaseline_actions_loss: 1.5314394235610962\n",
      "\tce_loss: 2.543034553527832\n",
      "\tmain_loss: 2.543034553527832\n",
      "Logs:\n",
      "\tstep_per_sec: 146.16610552975055\n",
      "\tcum_steps: 50250\n",
      "\treplay_size: 50250\n",
      "\tagent_eps: 0.35457142857142854\n",
      "\teval_time: 0.29305601119995117\n",
      "closed_loop_grid_world_goals_label_diff:\n",
      "\tx: 0.2\n",
      "\ty: 0.0\n",
      "\tavg_diff: 0.1\n",
      "\tavg_pos_diff: 0.0\n",
      "\tachieved_x: 0.8\n",
      "\tachieved_y: 1.0\n",
      "\ttotal_achieved: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10050it [01:09, 144.28it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning logging...\n",
      "Evaluating closed_loop_grid_world_goals_label_diff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 50/10000 [00:00<00:28, 354.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "\tactions_ce_loss: 0.9504319429397583\n",
      "\tbaseline_actions_loss: 1.5297832489013672\n",
      "\tce_loss: 2.480215072631836\n",
      "\tmain_loss: 2.480215072631836\n",
      "Logs:\n",
      "\tstep_per_sec: 142.96026223515068\n",
      "\tcum_steps: 60300\n",
      "\treplay_size: 60300\n",
      "\tagent_eps: 0.2253571428571428\n",
      "\teval_time: 0.4133620262145996\n",
      "closed_loop_grid_world_goals_label_diff:\n",
      "\tx: 0.0\n",
      "\ty: 0.0\n",
      "\tavg_diff: 0.0\n",
      "\tavg_pos_diff: 0.0\n",
      "\tachieved_x: 1.0\n",
      "\tachieved_y: 1.0\n",
      "\ttotal_achieved: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 9700/10000 [01:07<00:02, 148.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning logging...\n",
      "Evaluating closed_loop_grid_world_goals_label_diff\n",
      "train:\n",
      "\tactions_ce_loss: 0.9792702794075012\n",
      "\tbaseline_actions_loss: 1.5255439281463623\n",
      "\tce_loss: 2.5048141479492188\n",
      "\tmain_loss: 2.5048141479492188\n",
      "Logs:\n",
      "\tstep_per_sec: 147.30280853153678\n",
      "\tcum_steps: 70000\n",
      "\treplay_size: 70000\n",
      "\tagent_eps: 0.1006428571428571\n",
      "\teval_time: 0.3443770408630371\n",
      "closed_loop_grid_world_goals_label_diff:\n",
      "\tx: 0.0\n",
      "\ty: 0.0\n",
      "\tavg_diff: 0.0\n",
      "\tavg_pos_diff: 0.0\n",
      "\tachieved_x: 1.0\n",
      "\tachieved_y: 1.0\n",
      "\ttotal_achieved: 1.0\n"
     ]
    }
   ],
   "source": [
    "train_glamor(env_cls=env_cls,\n",
    "             model=model,\n",
    "             policy='open_loop',\n",
    "             final_eps=0.1,\n",
    "             eps_steps=int(7e4),\n",
    "             n_interactions=int(7e4),\n",
    "             k=k,\n",
    "             lr=5e-4,\n",
    "             policy_trials=50,\n",
    "             clip_p_actions=-3.15,\n",
    "             test_policies=['closed_loop'],\n",
    "             test_tasks=['train'],\n",
    "             eval_types=['labels'],\n",
    "             include_labels=None,\n",
    "             n_label_tasks=5,\n",
    "             n_video_tasks=5,\n",
    "             n_eval_tasks=5,\n",
    "             device=device,\n",
    "             gamma=0.5,\n",
    "             n_tasks=0,\n",
    "             train_tasks=task_dist,\n",
    "             replay_ratio=4,\n",
    "             log_period=int(1e4),\n",
    "             snapshot_period=int(1e5),\n",
    "             buffer_size=int(1e5),\n",
    "             min_step_learn=int(3e4),\n",
    "             frame_buffer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "\n",
    "Here we instantiate a planner, a policy, and a sampler that returns trajectories following this policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval\n",
    "from glamor.policies.closed_loop import ClosedLoopPolicy\n",
    "from glamor.policies.open_loop import OpenLoopPolicy\n",
    "from glamor.planner.sampling import SamplingPlanner\n",
    "from glamor.samplers.trajectory_sampler import TrajectorySampler\n",
    "\n",
    "planner = SamplingPlanner(model=model, \n",
    "                          gamma=0.5,\n",
    "                          n_actions=n_actions, \n",
    "                          device=device,\n",
    "                          num_trials=10,\n",
    "                          clip_p_actions=None)\n",
    "closed_loop_policy = ClosedLoopPolicy(planner=planner,\n",
    "                                      horizon=k + 1,\n",
    "                                      device=device,\n",
    "                                      action_space=env.action_space)\n",
    "open_loop_policy = OpenLoopPolicy(planner=planner,\n",
    "                                    action_space=env.action_space,\n",
    "                                    terminate=True,\n",
    "                                    horizon=k + 1,\n",
    "                                    device=device)\n",
    "sampler = TrajectorySampler(env_cls=env_cls,\n",
    "                            policy=closed_loop_policy,\n",
    "                            horizon=k,\n",
    "                            tasks=task_dist,\n",
    "                            lazy_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this multiple times to see different trajectories.\n",
    "\n",
    "trajs = sampler.collect_trajectories(n_interactions=None, \n",
    "                                     n_trajs=1)\n",
    "i = 0\n",
    "frames = [get_render(x) for x in trajs[i].obs]\n",
    "max_frame = np.stack(frames, axis=0).max(axis=0)\n",
    "task_frame = get_render(trajs[i].task.obs)\n",
    "combined_frame = max_frame / 2 + task_frame\n",
    "frame = np.concatenate([combined_frame, max_frame], axis=0)\n",
    "plt.imshow(frame);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
